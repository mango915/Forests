{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>sp</th>\n",
       "      <th>gx</th>\n",
       "      <th>gy</th>\n",
       "      <th>dbh</th>\n",
       "      <th>pom</th>\n",
       "      <th>date</th>\n",
       "      <th>codes</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105951</td>\n",
       "      <td>ACACME</td>\n",
       "      <td>610.0</td>\n",
       "      <td>104.7</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8924.0</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132160</td>\n",
       "      <td>ACACME</td>\n",
       "      <td>534.8</td>\n",
       "      <td>241.3</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8922.0</td>\n",
       "      <td>*</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132234</td>\n",
       "      <td>ACACME</td>\n",
       "      <td>539.4</td>\n",
       "      <td>242.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8922.0</td>\n",
       "      <td>DN</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132235</td>\n",
       "      <td>ACACME</td>\n",
       "      <td>538.8</td>\n",
       "      <td>242.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8922.0</td>\n",
       "      <td>DN</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191542</td>\n",
       "      <td>ACACME</td>\n",
       "      <td>282.7</td>\n",
       "      <td>177.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8825.0</td>\n",
       "      <td>*</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tag      sp     gx     gy    dbh  pom    date codes status\n",
       "0  105951  ACACME  610.0  104.7  119.0    1  8924.0     M      A\n",
       "1  132160  ACACME  534.8  241.3  116.0    1  8922.0     *      A\n",
       "2  132234  ACACME  539.4  242.3    NaN    0  8922.0    DN      D\n",
       "3  132235  ACACME  538.8  242.5    NaN    0  8922.0    DN      D\n",
       "4  191542  ACACME  282.7  177.5   75.0    1  8825.0     *      A"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"bci05.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data[data[\"status\"]=='A'][[\"tag\", \"sp\", \"gx\", \"gy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 299 different species\n"
     ]
    }
   ],
   "source": [
    "# 1) Species spotting\n",
    "types = data['sp'].value_counts().keys() \n",
    "S = len(types)\n",
    "print(\"There are {} different species\".format(S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Statistics on subplots\n",
    "\n",
    "Now we divide the total area of study (sampled plot) in 200 subplots of the same area.\n",
    "To do so we add two columns to the dataset, called $i$ and $j$, that are the result of division without rest respectively of $gx$ and $gy$ for 50 (0.5 hectars in each axis). Then we use some methods of pandas to encode in a 3D matrix the aboundance $x_k$ of each of the S species for each subplot $(i,j)$ and from that we can obtain the average presence of each species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Subsampling\n",
    "# 50 * 50 meters\n",
    "data[\"i\"], data[\"j\"] = data[\"gx\"]//50, data[\"gy\"]//50\n",
    "# a)\n",
    "cell_pop = data.groupby([\"i\", \"j\"])[\"sp\"].value_counts()\n",
    "# b) shaping them in a matrix\n",
    "cell_pop_M = cell_pop.unstack().stack(dropna = False).fillna(0).astype(int)\n",
    "cell_pop_M = np.array(cell_pop_M).reshape(20, 10, 299) # (i, j, specie)\n",
    "\n",
    "\n",
    "# this prints are just for understanding how to work with this dataset\n",
    "#print(\"Presence and aboundance in subplot (0,0) : \\n\", cell_pop_M[0,0,:], '\\n')\n",
    "#print(\"Aboundances of the various species: \\n\", cell_pop_M.sum(axis=(0,1)), '\\n')\n",
    "\n",
    "p_i = np.count_nonzero(cell_pop_M, axis = (0,1))/200\n",
    "#print(\"Absolute presence for each species: \\n\", presence, '\\n')\n",
    "#print(\"Relative presence for each species: \\n\", p_i, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the average squared difference between present and absent species in a subplot (that will be used as a constraint in section 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairing(configs):\n",
    "    # In each subplot there are more absent species than present (just an observation)\n",
    "    # S+ - S-\n",
    "    S_present = np.count_nonzero(configs, axis = (1)).flatten()\n",
    "    # S_absent = S - S_present -> S_pm = 2*S_present - S\n",
    "    S_pm = 2*S_present - S # Broadcasting\n",
    "    # constraint C_0 = < (S+ - S-)^2 >\n",
    "    return np.mean(np.power(S_pm,2))\n",
    "\n",
    "\n",
    "C_0 = pairing(cell_pop_M.reshape(200, 299))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Max Ent 1\n",
    "\n",
    "### Hamiltonian of the system for our constraints.\n",
    "\n",
    "We start considering a generic entropy:\n",
    "\n",
    "$$ S[\\{p_a\\}_{i=1,\\ldots,n}] = -K \\sum_{a=1}^n p_a ln(p_a), K > 0$$\n",
    "\n",
    "and following constraints:\n",
    "\n",
    "$$ \\sum_{a=1}^n p_a - 1 = 0 $$\n",
    "\n",
    "$$\\sum_{a=1}^n  p_a f_r(x_a) - <f_r(x)>_{obs} = 0 $$\n",
    "\n",
    "On the PDF we show that the corresponding Hamiltonian is:\n",
    "\n",
    "$$H(x_a, \\vec{\\lambda}) = - \\sum_{r=1}^{m}\\lambda_i f_i(x_a)$$\n",
    "\n",
    "\n",
    "### Analytical derivation of the tuned Lagrangian multipliers as functions of the constraints.\n",
    "\n",
    "Adopting the notation to our specific model, we set $K=1$, and rename:\n",
    "\n",
    "$x_a \\rightarrow \\vec{\\sigma^{(a)}}, m \\rightarrow S, f_r(x) \\rightarrow \\pi_i(\\vec{\\sigma}) = \\sigma_i$\n",
    "\n",
    "We start considering the following Hamiltonian:\n",
    "\n",
    "$H(\\vec{\\sigma}, \\vec{\\lambda}) = - \\sum_{i=1}^{S}\\lambda_i f_i(\\sigma) = - \\sum_{i=1}^{S}\\lambda_i \\sigma_i $\n",
    "\n",
    "Manipulating the partition function\n",
    "\n",
    "$$Z(\\vec{\\lambda}) = \\sum_{\\{\\vec{\\sigma}\\}} \\exp\\{\\sum_{i=1}^S \\lambda_i \\sigma_i\\} = \\\n",
    "    \\sum_{\\{\\vec{\\sigma}\\}} \\prod_{i=1}^S\\exp\\{\\lambda_i \\sigma_i\\} = \\\n",
    "    \\prod_{i=1}^S \\sum_{\\sigma_i = \\pm 1} \\exp\\{\\lambda_i \\sigma_i\\}  = \\\n",
    "    2^S \\prod_{i=1}^S \\cosh(\\lambda_i)$$\n",
    "\n",
    "Hence we can compute analytically the expected value for each variable $\\sigma_i$ for a given value of $\\vec{\\lambda}$\n",
    "\n",
    "$$ <\\sigma_i>_{model(\\vec{\\lambda})} = \\sum_{\\{\\vec{\\sigma}\\}} \\sigma_i P(\\vec{\\sigma}/\\vec{\\lambda}) = \\\n",
    "\\frac{\\sum_{\\sigma_i \\pm 1} \\sigma_i e^{\\lambda_i \\sigma_i}}{2 cosh(\\lambda_i)} = tanh(\\lambda_i) $$\n",
    "\n",
    "Now we impose $\\forall i$ $m_i = <\\sigma_i>_{model(\\vec{\\lambda})}$ \n",
    "\n",
    "$m_i = tanh(\\lambda_i) $\n",
    "\n",
    "and inverting the system we find\n",
    "\n",
    "$ \\lambda_i = +\\frac{1}{2} \\cdot ln(\\frac{1 + m_i}{1 - m_i} )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply the formula just obtained to compute the lagrangian parameters for the model Max Ent 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_i = 2*p_i - 1\n",
    "eps = 10e-06 # a small regularization in order to avoid devergences\n",
    "l_i = 0.5*np.log((1 - m_i + eps)/(1 + m_i + eps))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Max Ent 2\n",
    "\n",
    "Now we consider a new Hamiltonian\n",
    "\n",
    "$H(\\vec{\\sigma}, \\vec{\\lambda}, K) = - \\frac{K}{S}\\sum_{i,j}\\sigma_i\\sigma_j - \\sum_{i=1}^{S}\\lambda_i \\sigma_i$\n",
    "\n",
    "\n",
    "\n",
    "### Constraints for Max Ent 2\n",
    "\n",
    "The constraints that we are going to use are:\n",
    "* $m_i = <\\sigma_i>_{model} = C_i(\\vec{\\sigma}) $ with coupled parameters $\\lambda_i, i = 1,\\ldots, S$\n",
    "* $<(S_+ - S_-)^2>_{exp} = <(\\sum_{j=1}^{S}\\sigma_j)^2>_{model} = C_0(\\vec{\\sigma})$ with coupled parameter $\\lambda_0 = K/S$\n",
    "\n",
    "To initialize the Lagrange multipliers we have two possible choices: extracting them from a gaussian distribution centered in 0 or to take the initial $\\lambda_i$ as the one of the previous point and for $K'$ using a gaussian with variance that is a funtion of S. [WORK IN PROGRESS]\n",
    "\n",
    "### Gradient descent function\n",
    "\n",
    "The objective function that we want to minimize is the Kullbackâ€“Leibler divergence $D_{KL}(P_{exp}/P_{model})$.\n",
    "\n",
    "The derivatives of the KL-divergence w.r.t. the Lagrangian multipliers are:\n",
    "\n",
    "$$ \\frac{\\partial D_{KL}}{\\partial \\lambda_a} = <C_a(\\vec{\\sigma})>_{model}-<C_a(\\vec{\\sigma})>_{exp} $$\n",
    "\n",
    "More in concrete:\n",
    "\n",
    "$$\\frac{\\partial D_{KL}(t)}{\\partial \\lambda_0} = <(\\sum_{j=1}^{S}\\sigma_j)^2>_{model(t)} - <(S_+ - S_-)^2>_{exp}  $$\n",
    "\n",
    "$$\\frac{\\partial D_{KL}(t)}{\\partial \\lambda_i} = <\\sigma_i>_{model(t)} - m_i $$\n",
    "\n",
    "\n",
    "Thus the update rule for gradient descent will be:\n",
    "\n",
    "$$\\lambda_a(t+1) \\leftarrow \\lambda_a(t) - \\eta \\cdot \\frac{\\partial D_{KL}(t)}{\\partial \\lambda_a}$$\n",
    "\n",
    "\n",
    "### Stopping criteria\n",
    "Then we want to run the cycle of Metropolis and gradient descent until a stopping criteria is met.\n",
    "Possible choices are:\n",
    "* fixed number of iterations\n",
    "* margin of improvement under a certain threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metropolis as M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299,)\n"
     ]
    }
   ],
   "source": [
    "# initialize the lagrangian parameters (utilizied the l_i from MaxEnt1)\n",
    "l_0 = np.random.randn()\n",
    "\n",
    "#lagrange_multipliers = np.concatenate((np.array([l_0]), l_i))\n",
    "#lagrange_multipliers = np.random.randn(300)\n",
    "lagrange_multipliers = np.random.randn(299)\n",
    "print(lagrange_multipliers.shape)\n",
    "# define experimental constraints\n",
    "#exp_constraints = np.concatenate((C_0[np.newaxis], m_i))\n",
    "exp_constraints = m_i\n",
    "\n",
    "# define model functions\n",
    "pairing # <- just a reminder\n",
    "def model_m(configs):\n",
    "    # assuming configs have a shape of (n, S) with S = 299 \n",
    "    print(np.count_nonzero(configs, axis = 0))\n",
    "    print(config.shape[0])\n",
    "    \n",
    "    p_i = np.count_nonzero(configs, axis = 0)/configs.shape[0]\n",
    "    return 2*p_i - 1\n",
    "\n",
    "# model_m -> (299,)?, pairing -> (1,)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(model_configs, exp_constraints):\n",
    "    #update1 = pairing(model_configs) - exp_constraints[0]\n",
    "    #update2 = model_m(model_configs) - exp_constraints[1:]    \n",
    "    update2 = model_m(model_configs) - exp_constraints    \n",
    "\n",
    "    #gradient = np.concatenate((update1[np.newaxis], update2))\n",
    "    return update2 #<-gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "# the learning rate\n",
    "eta = 0.1\n",
    "\n",
    "# and the number of iterations\n",
    "max_iter = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'metropolis' from '/home/mango/Documenti/unipd/magistrale/complex_systems/Assigment1/metropolis.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook, tnrange\n",
    "\n",
    "mean_sq_loss = np.zeros(max_iter) # gradient square sum\n",
    "for i in tnrange(max_iter):\n",
    "    #instance of the class\n",
    "    model = M.Metropolis(lagrange_multipliers, exp_constraints, S, max_acceptance = 0.15)\n",
    "\n",
    "    configs = model.sample(100)\n",
    "    g = gradient(configs, exp_constraints)\n",
    "    #lagrange_multipliers[0] = lagrange_multipliers[0] - eta*g[0]/299\n",
    "    #lagrange_multipliers[1:] = lagrange_multipliers[1:] - eta*g[1:]\n",
    "    lagrange_multipliers = lagrange_multipliers - eta*g\n",
    "    #print(g)\n",
    "    mean_sq_loss[i] = np.power(g,2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(mean_sq_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_sq_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 506.21666000000005,
   "position": {
    "height": "40px",
    "left": "994.367px",
    "right": "14.6333px",
    "top": "94px",
    "width": "516.367px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
